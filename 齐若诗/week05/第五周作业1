作业一：
1.设计数据库
必须设计数据库。这个项目开发的核心任务之一就是构建一套支撑FAQ生命周期的关系型与非关系型存储体系。可以涉及：
（1）类目管理表： 存储链接1中的“一级类目”、“二级类目”。需要设计id, name, parent_id, level等字段，通过递归或路径枚举（Path Enumeration）来实现无限级分类。
（2）FAQ主表： 存储标准问题、回答内容（纯文本/语音/富文本）、生效/失效时间、创建人及所属类目ID。
（3）扩展/相似问表：存储链接2中提到的“相似提问”和“待选提问”。每一条FAQ主记录会关联多条相似问法，用于增加匹配的覆盖面。
（4）Redis：缓存高频被访问的FAQ，减少数据库压力，实现毫秒级响应。
（5）向量数据库（如Milvus或OpenSearch向量检索版）： 这是算法实现的关键。后端需要将FAQ的语义向量存储在此，用于执行近邻搜索（ANN）。
2. 模型
为了实现“用户的提问直接与历史提问进行相似度匹配”，构建一套检索式问答（Retrieval-QA）模型体系：
（1）召回模型（Recall）： 采用Bi-Encoder，将FAQ库和用户提问分别映射到同一个向量空间。
（2）排序模型（Rerank）： 采用Cross-Encoder，在初步筛选出最相似的Top-10个问题后，用更精细的模型对“用户问”和“库中问”进行一对一的深度语义匹配，以确保返回给用户的是最准确的那条。
（3）意图识别模型： 在匹配前，先判断用户是否在闲聊、咨询业务还是投诉，从而决定是否触发FAQ匹配。
3. 使用BERT
BERT（Bidirectional Encoder Representations from Transformers）是目前智能客服系统的“发动机”。具体应用如下：
（1）特征提取（Embedding）： 我们不直接比较文字，而是将FAQ中的标准问和相似问输入BERT，取其[CLS]位的输出或平均Pooling后的向量作为该问题的“数字指纹”。
（2）语义预计算： 后端开发在FAQ录入阶段，就调用BERT模型将所有问题预先转化为向量，存入向量库。这样当用户提问时，系统只需要计算一次用户提问的向量。
（3）微调（Fine-tuning）： 使用公司业务场景下的历史对话数据对BERT进行微调。例如，“流量”在电信客服里指上网数据，在物流客服里指货运量，通过微调让BERT学习到这种特定的行业语义。
（4）计算相似度： 用户的提问向量与库中向量进行余弦相似度计算。得分最高且超过设定阈值（如0.85）的，则直接返回对应回答。
4. 使用大模型
可以使用大模型作为“增强”手段引入，传统的FAQ系统要求“确定性”，即A问题必须回B答案。大模型存在“幻觉”风险，且成本高、速度慢。
但在阿里云的这种工作台场景下，大模型可以实现：
（1）相似问生成： 链接2提到需要手动录入相似提问。我们可以利用大模型（如通义千问）自动根据一个标准问生成20个语义相同但表述不同的相似问，极大地丰富知识库。
（2）拒识与兜底： 当BERT匹配不到相似度高的答案时，大模型可以基于文档（RAG模式）生成一个委婉的回答，或者引导用户进行人工转办，避免直接报“对不起，我不理解”。
（3）多轮引导： 如果用户的提问太模糊，大模型可以根据FAQ类目主动反问：“您是想咨询‘退款政策’还是‘物流查询’？”
